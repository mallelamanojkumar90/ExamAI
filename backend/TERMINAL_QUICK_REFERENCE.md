# ğŸ” Quick Reference: Reading Terminal Output

## When You Generate Questions, Look For:

### 1ï¸âƒ£ **RETRIEVED CONTEXT Section**
```
ğŸ“š RETRIEVED CONTEXT FROM PINECONE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Match #1:
    ğŸ“„ Source File: [filename.pdf]
    ğŸ“Š Subject: [subject]
    ğŸ“– Page: [page number]
    ğŸ¯ Relevance Score: [0.0 - 1.0]
    ğŸ“ Text Preview: [first 100 chars...]
```

**What to check:**
- âœ… Are the source files relevant to your subject?
- âœ… Are the relevance scores high (> 0.7)?
- âœ… Does the text preview look relevant?

---

### 2ï¸âƒ£ **RAG STATUS Section**
```
âœ… RAG STATUS: Using RAG CONTEXT
   ğŸ“š Total Context Chunks: [number]
   ğŸ“ Source Files Used:
      â€¢ [file1.pdf]
      â€¢ [file2.pdf]
```

**OR**

```
âš ï¸  RAG STATUS: Using PURE LLM KNOWLEDGE
   Reason: No relevant documents found in Pinecone
```

**What it means:**
- âœ… **RAG CONTEXT** = Questions based on YOUR documents
- âš ï¸ **PURE LLM** = Questions based on general knowledge

---

### 3ï¸âƒ£ **GENERATION RESULT Section**
```
GENERATION RESULT:
  Requested: [count] [subject] questions
  Generated: [count] questions
  Q1: [question preview...]
  Q2: [question preview...]
  ...
âœ… SUCCESS: Generated exactly [count] questions!
```

**What to check:**
- âœ… Does "Generated" match "Requested"?
- âœ… Do the question previews look relevant to the subject?

---

### 4ï¸âƒ£ **QUESTION SOURCE SUMMARY Section**
```
ğŸ“Š QUESTION SOURCE SUMMARY:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Questions generated using RAG
   Knowledge Source: Vector Database + LLM
   ğŸ“ Documents Used (2):
      â€¢ physics_chapter5.pdf
      â€¢ jee_problems.pdf
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**What it tells you:**
- ğŸ“š How many documents were used
- ğŸ“„ Which specific files contributed
- ğŸ¯ Whether RAG or pure LLM was used

---

## ğŸš¦ Quick Status Guide

| Symbol | Meaning | Action Needed |
|--------|---------|---------------|
| âœ… | Success / RAG Active | None - working as expected |
| âš ï¸ | Warning / Pure LLM | Consider uploading documents |
| ğŸ”„ | Retry in progress | Wait for completion |
| âŒ | Error occurred | Check error message |

---

## ğŸ“Š Relevance Score Guide

| Score Range | Interpretation | Quality |
|-------------|----------------|---------|
| 0.9 - 1.0 | Highly relevant | Excellent |
| 0.7 - 0.9 | Very relevant | Good |
| 0.5 - 0.7 | Moderately relevant | Fair |
| < 0.5 | Low relevance | Poor |

---

## ğŸ¯ What You Want to See

**IDEAL OUTPUT:**
```
âœ… RAG STATUS: Using RAG CONTEXT
   ğŸ“š Total Context Chunks: 5-10
   ğŸ“ Source Files Used:
      â€¢ [relevant_file1.pdf]
      â€¢ [relevant_file2.pdf]
      â€¢ [relevant_file3.pdf]

âœ… SUCCESS: Generated exactly 10 questions!

ğŸ“Š QUESTION SOURCE SUMMARY:
âœ… Questions generated using RAG
   ğŸ“ Documents Used (3):
      â€¢ [relevant files listed]
```

**This means:**
- âœ… Questions are based on YOUR curriculum
- âœ… Multiple documents provide diverse context
- âœ… Correct number of questions generated
- âœ… High-quality, specific questions

---

## âš ï¸ What to Watch For

**NEEDS ATTENTION:**
```
âš ï¸  RAG STATUS: Using PURE LLM KNOWLEDGE
   Reason: No relevant documents found

âš ï¸  Questions generated using PURE LLM KNOWLEDGE
   Knowledge Source: LLM's pre-trained knowledge only
```

**This means:**
- âš ï¸ No documents uploaded for this subject
- âš ï¸ Questions are generic, not curriculum-specific
- âš ï¸ You should upload relevant PDFs

**ACTION:** Upload textbooks/materials for this subject to Pinecone

---

## ğŸ“ Example: Good vs Needs Work

### âœ… GOOD - Physics with RAG
```
Subject: Physics
RAG Status: âœ… Using RAG CONTEXT
Source Files: 
  â€¢ ncert_physics_class11.pdf
  â€¢ jee_advanced_mechanics.pdf
  â€¢ physics_problems_solved.pdf
Relevance Scores: 0.85, 0.82, 0.79
Result: 10 curriculum-specific questions
```

### âš ï¸ NEEDS WORK - Chemistry without RAG
```
Subject: Chemistry
RAG Status: âš ï¸ Using PURE LLM KNOWLEDGE
Source Files: None
Result: 10 generic chemistry questions
Action: Upload chemistry textbooks
```

---

## ğŸ”§ Troubleshooting

| Issue | Likely Cause | Solution |
|-------|--------------|----------|
| Always shows "PURE LLM" | No documents uploaded | Upload PDFs via admin panel |
| Wrong subject in source | Metadata incorrect | Re-upload with correct metadata |
| Low relevance scores | Documents not relevant | Upload more specific materials |
| No matches found | Subject filter too strict | Check subject naming consistency |

---

## ğŸ’¡ Pro Tips

1. **Check source files first** - Verify they match your subject
2. **Monitor relevance scores** - Higher is better (aim for > 0.7)
3. **Track document usage** - Ensure all subjects have RAG coverage
4. **Compare question quality** - RAG questions should be more specific
5. **Keep terminal visible** - Watch the logs during generation

---

## ğŸ“ Need Help?

If you see unexpected output:
1. Check the full terminal output
2. Verify documents are uploaded to Pinecone
3. Ensure subject metadata matches your request
4. Check relevance scores
5. Review the source files listed
